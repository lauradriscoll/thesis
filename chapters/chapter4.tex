\chapter{Discussion and future experiments} \label{chapter_4}

\section{History-dependent population dynamics} \label{discussion:general}

We have used new experimental and analysis methods to explore the activity in the PPC neuronal population on single trials of an evidence accumulation task. These methods extend approaches that have been applied previously during evidence accumulation tasks in other animals \citep{Yang:2007in, Gold:2007fo, Raposo:2014df, Raposo:2012ju, Brunton:2013kg, Hanks:2015fy, Scott:2015eh}. Our work has identified two features of PPC activity that together motivate a novel algorithmic model for how evidence accumulation is performed in neuronal circuits. First, we have shown that each event during a trial, such as a new evidence cue or a behavioral choice, modified the dynamics of the PPC over a timescale of seconds. Surprisingly, the effect of each event, including evidence cues, was not a change in the tonic activity of a specific set of neurons; rather, each event altered the set of activity patterns that the population could occupy in the future and thus the transition probabilities between complex population activity patterns, often involving transitions between different sets of active neurons. This finding leads to a potentially generalizable rule in which transient inputs and activity patterns in the PPC ‘reverberate’ as long-lasting changes in the set of possible activity pattern transitions and trajectories, resulting in a short-term memory of each past input and activity pattern (Figure \ref{fig:3_15}d-f). This process was seemingly continuous in that the PPC activity pattern never appeared to reset, even after a trial was finished; rather, the PPC activity had an ongoing record of recent past events thus forming a continuous, gap-free short-term memory. Our findings support and extend previous work that described the PPC as an accumulator \citep{Shadlen:1996ga, Gold:2000hp, Yang:2007in, Hanks:2015fy, Britten:1992wx, Horwitz:1999ws} by proposing that accumulation might occur generally by means of ‘reverberation’ of all network activity changes and by demonstrating that this accumulation could occur as long timescale dynamics mediated by orderly transitions between transient and highly different activity patterns.

\bigskip
Second, we have shown that trials of the same type (e.g., identical evidence cues and choices) were highly variable, such that these trials did not converge to a single, low-variance activity pattern, but were instead represented by widely varying patterns of population activity (Figure \ref{fig:3_15}d-e). The diversity of activity patterns emerged because the PPC had information about many signals, including past events such as previous choices, reward outcomes, and evidence cues. Variability can therefore be considered, in part, as signals for non-measured or hidden parameters, beyond those parameters directly tested in an experiment (e.g., choice or net evidence), with the remaining variance likely due to biological and measurement noise. The presence of hidden signals impacts our analysis and interpretation of neuronal activity in that it may be inaccurate to consider activity in layer 2/3 of PPC as specific for a set of measured task parameters and to think of the representation of those parameters as a small set of noisy network activity patterns. For example, the neuron-neuron activity correlation structure remaining after the subtraction of activity resulting from a selected subset of task variables, typically referred to as ‘noise correlations’, may reflect, in some cases, ‘residual correlations’ due to additional signals in the PPC.

\section{Importance of single-trial population analyses} \label{discussion:single_trial_importance}

Our findings therefore underscore the importance of analyzing population activity on single trials. For example, averaging together highly variable trials might obscure important information in the population dynamics. When we simulated a pseudo-population of non-simultaneously recorded neurons (Methods \ref{methods:clustering_pseudopop}), we lost the ability to detect long timescale dynamics in the PPC. We could not for a given trial predict future and past activity patterns based on the trial’s current population activity pattern (Figure \ref{fig:3_7}g), suggesting that simultaneously measured neuron-neuron correlations are critical. Our new experimental and analysis methods thus combine and put into a new context features identified in previous studies, including heterogeneous activity patterns across neurons \citep{Meister:2013ca, Park:2014co, Jun:2010kj, Raposo:2014df, Rigotti:2013bo}, distributed representations of task stimuli including for non-relevant inputs \citep{Mante:2013ie, Safaai:2013jq, Petersen:2000tw, Rigotti:2013bo}, activity-dependent processing of stimuli \citep{Harris:2011gw, Safaai:2015jr, Curto:2009ga}, and the encoding of previous stimuli that indicates stimulus reverberation over time \citep{Bernacchia:2011bb, Donahue:2015fi, Seo:2007jp, Seo:2007jv, Nikolic:2009cf, Klampfl:2012cm, Seo:2009jl, Sugrue:2004ex, Chaudhuri:2015jb, Murray:2014ee, Yang:2012hw}. 

\section{Inconsistencies with winner-take-all models} \label{discussion:wta}

Our findings are inconsistent with traditional neuronal implementations of evidence accumulation \citep{Wong:2006in, Machens:2005en, Wang:2002kn}. These models propose a winner-take-all competition that evolves over time between distinct pools of neurons, reaching an attractor state once a choice has been made. These models rest on several key predictions that were not apparent in our data. First, traditional implementations of winner-take-all models predict that on different trials with the same choice the population activity converges to the same, low variance pattern (attractor, which could potentially take multiple possible forms, such as a point in activity state space or a trajectory). In contrast, we found that the same trial types (and choices) did not converge to a single pattern and instead consisted of highly different activity patterns. Second, published model implementations propose that the neurons in a given pool have homogeneous and long-lasting activity patterns. Instead, consistent with our previous results \citep{Harvey:2012du}, we found that neurons in the PPC were highly heterogeneous, with transient and time-varying activity (Figures \ref{fig:3_3}a, \ref{fig:3_4}, \ref{fig:3_5}a-b, \ref{fig:3_6}d). Third, traditional winner-take-all implementations predict that activity eventually reaches the same attractor state for all identical choices, erasing the history of previous events. In contrast, we observed that, throughout a trial, history signals were present for many events, including the sequence of previous cues and outcomes from previous trials, suggesting that the population activity must not have converged to a single attractor for each choice (Figures \ref{fig:3_12}, \ref{fig:3_15}a). Finally, most implementations of winner-take-all competitions involve mutual inhibition between competing pools of neurons that should result in negative population activity correlations between trials with different choices. Instead, we observed a correlation coefficient close to zero for such trial pairs (r = -0.01 $\pm$ 0.003, mean $\pm$ s.e.m. across datasets). Although our results are inconsistent with current neuronal implementations of winner-take-all dynamics, they could be consistent with emerging, but not fully explored, models in which a winner-take-all circuit is embedded within a network with history-dependent dynamics \citep{Klampfl:2013gq} or in which activity in a winner-take-all circuit is drawn towards, but never converges to, dynamically changing attractors.

\bigskip
Our experiments were not designed to test how accumulation might be used for decision-making, such as in relation to drift-diffusion models. Often, accumulation and drift-diffusion have been tightly linked to winner-take-all mechanisms, but we propose that alternative algorithms and implementations, such as the one suggested by our results, could underlie these processes. In this case, our results suggest that the accumulator would be leaky over the timescale of seconds because the timescale of structured transitions we measured and of the memories of past events decayed over seconds. Also, our results provide the important constraint that a single value for a decision variable would likely be represented by many different activity patterns. Similarly, a decision bound would likely be read out from a distributed representation of many signals such that many different activity patterns might represent the same bound (Figure \ref{fig:3_15}d-e).

\section{A general rule for dynamics in the PPC} \label{discussion:model}

We propose a general rule for PPC dynamics in which any input that triggers a change in activity will have a long-lasting effect on future activity patterns due the long timescale dynamics of changes in transition probabilities. In the case of evidence accumulation, the evidence cues would not be privileged over other inputs; rather, evidence cues, like all other inputs, would help generate new activity patterns and thus new transition probabilities to future activity patterns. With multiple evidence cues offset in time, the changes in the transition probabilities would cascade such that the activity pattern following a sequence of cues would in part be defined by, and thus contain information about, the precise order of cues. Different sequences of cues would therefore result in unique activity patterns, as we have shown (Figure \ref{fig:3_15}a). As a result, the same net evidence, choice, and likely decision variable would not converge to the same activity pattern from trial to trial, but rather would form a diverse set of activity patterns. We predict that prior to learning of a task, these activity patterns would not be associated with one another. Rather, through learning, the weights of connections onto a downstream readout network could be modified to establish a decision plane for choice or a manifold for net evidence. The readout network would therefore be able to associate the initially arbitrary sets of activity patterns with a task-specific meaning and behavioral output, as has been demonstrated in computational models \citep{Buonomano:2009cw, Briggman:2005jd, Hoerzer:2014cz} (Figure \ref{fig:3_15}d). The low-dimensional projection in the readout network could be consistent with previous recordings of ramping activity during evidence accumulation tasks \citep{Shadlen:1996ga, Yang:2007in, Hanks:2015fy, Britten:1992wx, Horwitz:1999ws, Murakami:2014jl}. This model argues that the PPC has the general role of a ‘reverberator’ of its inputs and that evidence accumulation occurs as a specific example of this general feature. This new model is consistent with the theoretical framework developed in reservoir computing \citep{Jaeger:2004hj, Maass:2002kf, Buonomano:2009cw, Buonomano:1995fm, Verstraeten:2007jw}. 

\bigskip
Importantly, our proposed algorithm offers significant advantages over a winner-take-all competition. In a winner-take-all competition, evidence accumulation would occur through an explicit, abstract signal for accumulated evidence. Such a signal is typically implemented in a highly specialized network architecture, such as a point attractor network, that is fine tuned for a specific type of input, such as visual cues during virtual navigation in our case \citep{Wong:2006in, Machens:2005en, Wang:2002kn}. In contrast, our proposed model would allow for the same network to flexibly scale for decision-making with multiple alternatives and to perform computations relevant to many diverse and novel tasks. This flexibility could be achieved through plasticity in readout weights, rather than through the construction of a new circuit architecture for each task \citep{Legenstein:2008gx, Gutig:2006cz, Jaeger:2004hj, Sussillo:2009gh, Barak:2013bg, Sussillo:2014dy, Rosenblatt:1958vca, Hoerzer:2014cz, Mante:2013ie}. We consider this advantage important for the PPC, which, as we have shown, contains many signals in the same population of neurons and thus likely contributes to many learned behaviors in parallel.

\section{Developing neuronal implementations of history-dependent dynamics} \label{discussion:neural_implementation}

The current work primarily advances our understanding of the algorithm performed by the PPC while providing some constraints on the neuronal implementation, such as a distributed representation of task features, time-varying activity, and predictable transitions between activity states defined by complex patterns of activity in the neuronal population. However, to further improve our understanding of this model's plausibility and how information is processed in the PPC, future work will be required to generate a variety of potential neuronal implementations of this algorithm. These neuronal implementations could be based on a variety of potential architectures. However, they should each make experimentally  testable predictions which will allow us to distinguish between them.  

\section{Additional experimental tests} \label{discussion:additional_tests}

Our work suggests that layer 2/3 of the PPC may serve as a general purpose `reverberator' whose goal is merely to maintain an implicit, distributed memory of inputs for as long as possible. This architecture would be independent of specific tasks and could therefore be generated early in life via mechanisms such as unsupervised learning. As an animal learns a task, downstream readout networks would gradually converge to the appropriate readout weights to optimally recover the identity of task-relevant inputs \citep{Legenstein:2008gx, Gutig:2006cz, Jaeger:2004hj, Sussillo:2009gh, Barak:2013bg, Sussillo:2014dy, Hoerzer:2014cz}. One potential advantage of this model is that, because the reward signals used in mechanisms such as reinforcement learning are sparse \citep{Sutton:2011wc}, it may be easier to learn a limited set of readout weights than a large number of recurrent weights.

\bigskip
If activity in layer 2/3 of the PPC serves as a general purpose reverberator of inputs in a task-independent manner, its activity dynamics should not change much over the course of learning. One would therefore expect that, even in animals early in training, task-relevant events would remain discriminable over seconds. To test this result experimentally, one could record the activity of neuronal populations before, during, and after learning of a new task. If layer 2/3 of the PPC does in fact play the role of a general purpose reverbarator of inputs, the activity dynamics should not change. However, if the internal PPC dynamics remain unchanged over learning, but the impact of task-relevant events on network activity increases over learning, task-relevant events may not be discriminable early in training simply because they do not exert a pronounced impact on PPC activity. The results of this experiment may therefore be difficult to interpret. 

\bigskip
As a related analysis, one could train individual mice to perform multiple tasks within the same behavioral session. If layer 2/3 of the PPC serves as a general purpose reverberator of inputs, one would again expect that the activity patterns in the PPC would be remain unchanged and therefore be similar in both tasks. Recently, Mante and colleagues observed that during a variant of the random dot motion task in which monkeys had to discriminate either color or motion on alternating blocks of trials, population activity in the PFC was similar regardless of whether motion or color was behaviorally relevant \citep{Mante:2013ie}. This result is consistent with the predictions of our model, but further tests will be required to determine whether this result generalizes to the PPC and other tasks.

\bigskip
Because our model postulates that the primary change over the course of learning is the appropriate modification of readout weights, the prevalence of readout networks should gradually increase over the course of learning. If these readout networks include the neurons recorded previously \citep{Gold:2007fo,Hanks:2015fy,Shadlen:1996ga}, we would expect these neural populations to grow in size, increase their selectivity, or both during task learning. To test this experimentally, one could record from populations of neurons known to exhibit task selectivity before, during, and after learning.  However, because these predictions are relatively unconstrained, the results of these experiments may be difficult to interpret. For example, it is possible that individual neurons with high task selectivity exist merely as a byproduct of the history-dependent dynamics described in Chapter \ref{chapter_3}. This would suggest that an explicit readout network would not be necessary. However, an implicit readout network, in which a high-dimensional, distributed representation is transformed into a different high-dimensional, distributed representation might still be present. This result would still be consistent with both our data and our model. We must therefore work to further constrain these models to generate clear, testable predictions.

\bigskip
A variety of studies have recently provided support for the notion of a `hierarchy of timescales' across cortex, in which the time constant of neuronal activity is shorter in areas closer to the sensory periphery, such as visual and auditory cortex, and longer in association cortex, including PPC and PFC \citep{Bernacchia:2011bb,Murray:2014ee,Yang:2012hw}. This work has primarily focused on the time constant of activity for individual neurons. However, one could use analyses similar to those described in Chapter \ref{chapter_3} to instead measure the time constant of \textit{predictability} for population activity in different cortical areas. For example, if such a hierarchy exists, one might find that trial-trial variability is predictive of future variability for longer in the PPC than in V1. While this result would be consistent with the interpretation of previous work, it would suggest a substantively different mechanism based on history-dependent population dynamics.

\bigskip
Because our model proposes that the PPC acts in a general-purpose manner, we would expect that certain inputs to layer 2/3 of the PPC are not privileged over others. In other words, inputs which are behaviorally relevant should not have a greater impact on PPC activity than inputs which are behaviorally irrelevant. To test this, one could design a task which contains signals which are behaviorally irrelevant by design. For example, one could use a variant of the fixed association evidence accumulation task in which cues can either be black or white, but still appear on either the left or the right side of the T-maze. The mouse's goal would still be to determine whether more cues were on the left or the right, regardless of the color of each cue. The location of each cue would therefore be behaviorally relevant, while it's color would be behaviorally irrelevant. One could then ask whether cue color could be decoded from PPC population activity independent of cue location. Because cue location and color may have different visual salience, one would have to perform the experiment in the opposite contingency as well (e.g., in which cue color is behaviorally relevant, and cue location is behaviorally irrelevant).

\section{Recreating history-dependent dynamics \textit{in silico} with recurrent neural networks} \label{discussion:RNN}

As a proof of principle experiment, it would be useful to demonstrate that such a model could successfully perform tasks \textit{in silico}. The first step of this experiment would be to train a artifical neural network to recapitulate the dynamics observed \textit{in vivo}, independent of a specific task. As a first test, one could use a recurrent neural network (RNN) without spiking (i.e., a rate network). One advantage of such networks is that effective techniques for learning appropriate recurrent weights developed in computer science, such as backpropagation through time, can be used \citep{LeCun:2015dt}. However, in contrast to traditional supervised learning approaches in which RNNs are trained to produce a desired output, the RNN in this experiment would be trained primarily to maintain discriminability of inputs for as long as possible.  Importantly, because neurons in layer 2/3 of the PPC exhibited transient dynamics (Figures \ref{fig:3_3}a, \ref{fig:3_4}, \ref{fig:3_5}a-b), an additional constraint imposing transiency would be added. This constraint would significantly increase the difficulty of this task by forcing the RNN to maintain discriminability of inputs through a variety of highly different activity patterns, as we observed. These objectives can be formalized as a differentiable loss function which penalizes the prolonged activity of individual neurons and rewards discriminability of inputs over long timescales (for example, by encouraging the maximization of the Euclidean distance between trial pairs with different inputs long after input offset). To test the similarity of the RNN's dynamics with those observed \textit{in vivo}, analyses similar to those presented in Chapter \ref{chapter_3} could be used to ensure consistency with experimental results. 

\bigskip
Once an RNN has been trained to produce history-dependent dynamics, the weights of the RNN can be fixed. Readout networks would then be trained to perform a variety of tasks as inputs are delivered to the RNN, including evidence accumulation and delayed-match-to-sample tasks like those described in Chapter \ref{chapter_2}. A variety of learning rules could be learned, including those which are biologically implausible, such as backpropagation, as well as biologically plausible learning rules, such as those based on local synaptic computations \citep{Legenstein:2014gp}. If the same RNN with the same weights can be used to perform a wide variety of tasks effectively (with different readout networks for each task), it would serve as an effective proof of principle that models based on reservoir computing are plausible. 

\bigskip
RNNs trained to recapitulate history-dependent dynamics could further be used to generate novel experimental predictions. For this purpose, artificial neural networks (ANNs) possess two key advantages over actual neural networks. First, ANNs provide the experimenter with a perfect, noiseless measurement of the activity of every neuron in the network at every time point. In contrast, our methods for monitoring activity in real neural networks are limited both in the number of neurons we can simultaneously record as well as the noise injected by our measurement techniques. Second, ANNs can be easily manipulated at a fine scale. For example, in section \ref{sec:chap3_distributed}, we found that task-relevant information was distributed across large populations of neurons, including those neurons that were individually non-selective for task features (Figure \ref{fig:3_3}). However, we cannot directly test \textit{in vivo} whether neurons which have high choice selectivity are necessary for the neuronal computation. In an ANN, however, we could easily set the activation of all highly selective neurons to zero. The deficit in network performance in response to this targeted inactivation would directly test the necessity of these neurons for these computations. Of course, ANNs also have a critical disadvantage: they are artificial and may exhibit activity dynamics which are radically different from those present in real neural networks. The advantages provided by ANNs should therefore be used primarily for rapid \textit{in silico }experiments, with the ultimate goal of generating predictions which can be tested in real neural networks \textit{in vivo}. 








