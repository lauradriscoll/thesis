\chapter{Dynamic reorganization of neuronal activity patterns in parietal cortex} 

\vspace*{-44pt}

Laura N. Driscoll, Noah L. Pettit, Selmaan N. Chettih, Matthias Minderer, and Christopher D. Harvey

\smallskip
\textit{This and the following chapters are a modified version of a submitted manuscript.}

\vspace*{50pt}

\section{Introduction} \label{sec:chap3_intro}

Here we tested if, in the mouse posterior parietal cortex (PPC), representations of learned associations between arbitrary stimulus-action pairings stabilized after these associations had been learned to expert levels. We developed methods to track the activity of populations of neurons and behavioral patterns across weeks as mice performed a navigation-based decision task in virtual reality at near-perfect levels. We focused on activity in PPC because it is essential for performing this task and in rodents is considered to function in learned sensorimotor associations, including during navigation (Harvey et al., 2012; McNaughton et al., 1994; Nitz, 2006; Whitlock et al., 2012). We found that activity patterns in individual neurons changed greatly over the course of days and weeks, such that the population of neurons that provided the most task-relevant information drifted over time. Despite changes in single cells over time, the PPC population maintained a steady state with the same statistics of population activity properties across weeks, such as, for example, a consistent distribution of the fraction of neurons active at each point in the trial. Information about the task could be decoded above chance for weeks using a fixed decoder, indicating that a stable readout of population activity could exist, despite changes in individual neurons. Also, representations of newly learned cue-response relationships were incorporated without perturbing existing representations. We propose that drift in neuronal activity patterns could be important in PPC for mediating a tradeoff between stable encoding of information and flexibility for incorporating new information.

\section{Results} \label{sec:chap3_results}

We trained mice to perform a two-alternative forced-choice task based on navigation through a T-maze in visual virtual reality (Harvey et al., 2012) (Figure 1A). At the beginning of the T-stem, mice saw one of two possible visual cues (white walls or black walls). Mice then ran through a short delay period portion of the T-stem in which the walls were identical between trial types. Upon reaching the T-intersection, mice had to report a choice about the cue?s identity by making a left or right turn to receive a reward. Mice learned this task over 4-6 weeks of training and reached expert behavioral performance that was mostly stable over weeks (Figure 1B). 

\subsection{Tracking behavior and neuronal activity over weeks} \label{sec:chap3_track_neuron_behavior}

During the task, we imaged the activity of hundreds of layer 2/3 PPC neurons simultaneously using volumetric two-photon calcium imaging (Peron et al., 2015b). Imaging locations were identified based on stereotaxic coordinates, and separate experiments revealed that these coordinates corresponded to a location anterior to cortical regions identified using retinotopic mapping. Here we call this region PPC and note that recent work from the Allen Brain Institute calls this regions VisA and that this regions is medial to what previous work has called secondary visual area A (Methods). Imaging sessions were performed typically every day with occasional one-day gaps between sessions (Supplementary Figure S1). On each day we identified the same field-of-view so that we could track activity patterns of neurons across time (Figure 1C-D). We developed a conservative approach to ensure as best as possible that we identified the same neurons across imaging days. First, we identified fluorescence signal sources (putative cells) on each day independently. Signal sources were selected on the basis of temporally correlated fluctuations between pixels, rather than using manual, anatomical selection methods that can fail to separate nearby cells, dendrites, and axons (Hamel et al., 2015; Peron et al., 2015a). Second, to match putative cells across all imaging days, we used a custom algorithm based on distance between regions-of-interest (ROIs) and similarities in the fluorescence images surrounding each ROI. Finally, we visually compared each identified cell across all days to ensure that each cell appeared consistent in the anatomical images and had highly similar ROIs assigned to it (Figure 1D). We only considered cells on days in which they were identified; other days, in which we could not with high confidence identify the cell, were excluded from our analysis, such that not every cell was identified on every day. This approach was aimed to minimize mislabeling of neurons across days and was intended to be conservative compared to previously developed methods (Huber et al., 2012; Liberti et al., 2016; Peron et al., 2015b; Peters et al., 2014; Poort et al., 2015; Ziv et al., 2013) (see Supplementary Figure S2 and Methods for a full discussion).  

\subsection{Necessity of PPC activity for post-learning performance of the task} \label{sec:chap3_necessity}

The activity patterns of PPC neurons on a single imaging day were consistent with those reported previously (Harvey et al., 2012; Morcos and Harvey, 2016). On each day, individual neurons were transiently active, with different neurons active at different time points, such that PPC activity tiled the entire duration of a trial (Figure 1E). Many of these responses were reliable and selective for a particular trial type. For example, some cells were more active on black cue-right turn trials than on white cue-left turn trials or vice versa.

\bigskip

The activity in the PPC appeared necessary for the mouse to perform the behavioral task. We virally expressed channelrhodopsin-2 in parvalbumin-expressing inhibitory interneurons at a location centered at the PPC and activated these neurons to inhibit excitatory activity on a subset of trials. Inactivation of PPC decreased the mouse?s behavioral performance from ~85 $\%$  correct to just above chance levels (Figure 1F). These results were obtained days or weeks after the mouse achieved plateau behavioral performance, suggesting that PPC activity was necessary for performing the task even in the post-learning phase. These results were in agreement with our earlier work that used pharmacological methods to inactivate the PPC and other studies showing a role for the rodent PPC in visual decision tasks (Goard et al., 2016; Harvey et al., 2012; Licata et al., 2016; Raposo et al., 2014). We note, however, that although inactivation was centered on PPC, such activity manipulations may not be isolated solely to PPC, as has been shown in other systems.

\subsection{Reorganization of sequential activity across maze locations} \label{sec:chap3_peaks}
To compare the activity patterns of neurons across days, we first focused on sequential activity throughout a trial. On each day, a sequence of neuronal activity was present (Figure 2A, top left, center, and bottom right panels). To determine whether this sequence of activity was the same from day to day, we sorted neurons based on where in the maze they had a reliable peak of activity. We then used the same sorting to look for the same sequence of activity on earlier or later days. Strikingly, the sequence of activity that was present on one day was largely different on other days (Figure 2A). Cells that had a significant peak of activity in the maze on a given day were unlikely to have a significant peak of activity at the same or nearby position after long intervals (Figure 2B). Over time this likelihood of a consistent peak position approached levels expected from a random reorganization of neuronal identities (Figure 2B). These changes resulted from cells with a peak of activity on one day either losing that peak of activity or having a shift in the peak?s location on subsequent days, both of which increased in likelihood as a function of time from when a peak was identified (Figure 2D). In some cases, peaks shifted by distances larger than one meter. The loss of peaks of activity was offset by an approximately constant rate at which cells initially lacking a peak of activity gained an activity peak (Figure 2D), resulting in a consistent fraction of active cells with significant peaks over the imaging period of weeks (22.0 ± 0.5$\%$ of neurons, mean ± sem) (Figure 2C). Together these results indicate that the same activity patterns were not repeated for long time periods.

\subsection{Different populations of neurons with trial type-specific activity patterns across days} \label{sec:chap3_single_cell_decoding}
We also investigated changes in activity patterns that could be related to information about the trial type. Specifically, we asked if the neurons that had different activity patterns on trials with different cues and choices, and thus provided information potentially useful for solving the task, were the same across time. For each neuron on each day, we used a decoder to quantify how well that neuron?s activity across the entire duration of a single trial could predict the trial type (white cue-left turn vs. black cue-right turn, correct trials only). On a given day, a significant fraction of active neurons had a decoding accuracy above chance (29.1 ± 1.1$\%$ of neurons, mean ± sem, with p < 0.05 compared to decoding with shuffled trial labels). Neurons that had high decoding accuracies on a given day, and thus different activity patterns between trial types, did not necessarily have significant decoding accuracies on subsequent days (Figure 3A and 3B). The large majority of neurons that were identified on more than 15 imaging days only had above chance decoding accuracy on less than half of those days (Figure 3C). Moreover, only 1.6$\%$ of these neurons had significant decoding accuracy on all days in which they were identified. The likelihood that a cell with greater than chance decoding accuracy on a given day also had significant decoding accuracy on a subsequent day decreased with the interval between compared days (Figure 3D). Over time the likelihood that a cell maintained significant decoding accuracy decreased to levels approaching those consistent with a random reorganization of cell identities (Figure 3D). We tracked the subpopulation of neurons that was the most highly informative about trial type on a given day. Over time, the distribution of decoding accuracy within this subpopulation approached and largely overlapped with the distribution of the entire population, indicating that this subpopulation was not a special set of highly selective neurons across all time points (Figure 3E).

\bigskip

We also examined if the neurons with selective activity for one trial type (e.g. black cue-right turn trials) switched to having a preference for the other trial type (e.g. white cue-left turn trials) (Figure 3F-H). The most highly selective cells for each trial type over time often lost their selectivity or gained additional selectivity, at other points in the maze, for the other trial type (Figure 3F-G). We tracked the neurons that had the strongest preferences for each trial type on a given day (Figure 3H). Over days, the trial type preferences of these neurons approached that of the entire population. Only a small fraction of neurons switched from having statistically significantly higher activity on one trial type to having statistically significantly higher activity on the opposite trial type (4.7 ± 1.7$\%$ of cells, mean ± sem; lower bound for chance: 1.4 ± 0.7$\%$ based on switches within a day using a hold out set; upper bound for chance: 45 ? 50$\%$ based on switches in selectivity when cell IDs were shuffled across days). Switches in trial type preferences were thus rare from one day to the next, and gains or losses of selectivity were more common. Together these results indicate that the population of neurons that had trial type-specific information was largely different across days, with larger differences in these populations over longer time windows. 

\subsection{Using a generalized linear model to compare relationships between neuronal activity and behavioral features across days} \label{sec:chap3_glm_intro}

These findings together provide evidence that major changes and reorganization of neuronal activity patterns occurred during stable performance of a behavioral task. However, these analyses only considered two aspects of the task (position in the maze and trial type) and did not include other task features that could potentially be represented in the neuronal activity. For example, PPC has been considered to be important for movement planning and could thus have activity related to the running patterns of the mouse (Andersen and Cui, 2009; Nitz, 2006; Whitlock et al., 2012). In addition, PPC receives inputs from visual areas and might have activity related to the movement of visual stimuli projected on the screen, such as during turning compared to forward motion (Harvey et al., 2012; Oh et al., 2014). We wanted to understand whether behavioral variability across days could explain the changes in neuronal activity or alternatively if these changes were due primarily to single neurons having different relationships between their activity and the behavior of the mouse across time. We therefore developed an approach to describe an individual neuron?s activity on single days based on a large number of variables that described the task and mouse?s behavior. We developed a generalized linear model (GLM) in which we modeled the activity of an individual neuron based on the running patterns of the mouse on the spherical treadmill, the virtual maze position (visual scene), the trial type, reward events, and whether the mouse was in the inter-trial interval period (Friedman et al., 2010; Park et al., 2014) (Supplementary Figure S3 and S4). We fit the relationship between a cell?s activity and these behavior and task features to develop a model of that cell?s activity-behavior relationship. We tested the quality of this model by predicting the cell?s activity based on the behavioral and task features in a subset of trials not used for fitting. If the predicted activity closely matched the real activity, we concluded that our model could describe the activity-behavior relationship for the cell on that day. Across cells, models were able to explain a large fraction of neuronal activity (57.9 ± 2.6$\%$ of cells, mean ± sem, had significant fits measured as the explained deviance in the neuronal activity compared to a null model) (Supplementary Figure S5). We fit separate models for each neuron on each day. The distribution of model prediction qualities for each day across the population was consistent throughout the duration of our several week study (Supplementary Figure S5D).

\bigskip

We used these models to compare the relationship between a cell?s activity and behavioral features across days. Using the model of a cell?s activity-behavior relationship fit on a single day, we predicted the cell?s activity based on behavior features in other days (Figure 4A and B). If the model developed on one day was able to predict activity on a subsequent day, then we concluded that a consistent activity-behavior relationship existed. In contrast, if a model developed on one day failed to predict the activity on subsequent days, then we concluded that a consistent activity-behavior relationship was absent. This approach has the potential to track stable relationships between neuronal activity and behavior features across days that traditional approaches might miss. For example, if a neuron had activity related to the running patterns of a mouse and if these running patterns changed relative to position in the maze across days, the GLM could potentially reveal a stable activity-behavior relationship over time that would be missed if only maze position were analyzed. Importantly, behavioral features, such as running speed and trial duration, were variable across trials, but maintained a similar distribution and range of values on each day, suggesting that models should be transferable across days (Supplementary Figure S6). We limited effects due to fitting procedures, such as regularization, and due to correlated task variables by fitting and testing bidirectionally for each pair of days (see Methods for a full discussion). 

\subsection{Changing activity-behavior relationships in single neurons over days} \label{sec:chap3_activity_behave_relation}

Models of activity-behavior relationships developed on a given day were, on average, able to predict activity patterns well on neighboring days, but did a poor job of predicting activity patterns as the time between the compared days increased (Figure 4C). Over long intervals, model predictions eventually reached that of a null model (for intervals greater than 17 days), indicating that a cell?s activity-behavior relationship was generally inconsistent over weeks (Figure 4C). We also quantified similarity of models for a given cell across days using Kendall rank correlations of model parameters and found a comparable decay over time (Supplementary Figure S5F). The changes in these activity-behavior relationships were made up of cells that lost well-modeled relationships, gained well-modeled relationships, and switched relationships across days. To quantify the prevalence of these events, we used a statistical threshold, based on shuffled data, to binarize model performance into models that predicted activity patterns above chance levels (significant predictions) and models that provided poor predictions of activity (Methods). We then compared pairs of models fit on separate days for a given cell. If the models developed on one day provided good predictions of the activity patterns on the other day, then the cell was considered to have a consistent activity-behavior relationship (Figure 4D). Instead, if one model with a significant prediction of activity could be developed for one day?s activity but not for the other day?s activity, then the cell was considered to have lost or gained an activity-behavior relationship (Figure 4D). If models with significant predictions could be developed on both days but these models provided poor predictions of activity on the other day, then the cell was considered to have switched activity-behavior relationships (Figure 4D). The likelihood that a cell lacking an activity-behavior relationship gained such a relationship remained constant throughout the imaging period of weeks (26.8 ± 0.01$\%$ of cells) (Figure 4E). As the time interval between the compared days increased, the likelihood that a cell had a consistent relationship decreased, and the likelihood that a cell lost or switched a relationship increased (Figure 4E). After ~20 days, a cell that had a well-described activity-behavior relationship was more likely to have lost this relationship or switched to a different relationship than to have maintained its original relationship (Figure 4E).

\bigskip

The rates at which neurons had changes in their activity-behavior relationships varied greatly (Figure 4F). For each neuron, we calculated the likelihood that a model developed on one day provided a significant prediction of another day?s activity (Figure 4G, left) and fit an exponential to this likelihood over time to define a metric of consistency for each cell (Figure 4G, right). Some neurons had slow decays and thus had relatively consistent activity-behavior relationships, whereas others had fast decays indicative of rapid changes. Over a 20 day interval, the large majority of neurons had a low likelihood of consistent models (Figure 4H). Only 7.3$\%$ of neurons had consistent activity-behavior relationships over the entire interval (defined as > 95$\%$ significant predictions after 10-20 days). To understand if the neurons with the most and least consistent activity-behavior relationships represented different types of behavioral information, we examined the contribution of various parameters to each cell?s activity (the extent to which the behavioral parameter of interest modulated a given cell?s model prediction). Cells with the most consistent and least consistent relationships had a distribution of contributions for trial type, position in the maze, running pattern, and inter-trial interval activity that overlapped with the distribution in the full population (Figure 4I). However, neurons with the least consistent relationships more often had greater contributions from trial type and maze position than neurons with the most consistent relationships (Figure 4I). Our results therefore suggest that there was a continuous distribution of stability in activity-behavior relationships across neurons, with activity related to learned task features (trial type and maze position) possibly having less consistency across time. 

\bigskip

The changes in activity-behavior relationships did not reflect independent relationships across days. Rather, consistent relationships in the recent past were predictive of consistent relationships in the short-term future. Neurons with a consistent activity-behavior relationship for two or more consecutive days prior to a particular imaging day were more likely to maintain that relationship than neurons which had a consistent relationship for only one of the immediately preceding imaging days (Figure 4J). These results suggest that neurons potentially operated with modes of activity that tended to persist for neighboring days such that a neuron?s activity on each day was not independent of the recent history of its activity. However, the predictive power of recent consistency fell off after ten days, suggesting there was not a separate population of permanently consistent cells (Figure 4J).

\bigskip

The GLM analyses therefore suggest that the changes in activity we observed were likely due to unstable activity-behavior relationships, rather than changes in behavioral patterns across days. We further supported this finding by comparing the similarity of population activity patterns on trials with the most similar or least similar behavioral patterns across all days. The population activity was more similar on those trials with more similar behavioral features, measured as correlations between population activity vectors (Supplementary Figure S7A). However, the difference in activity similarity between the most and least similar behavioral trials was small compared to the population activity changes across time (Supplementary Figure S7A). In addition, we did not observe any evidence that the mouse forgot and re-learned the task on each day because mice performed at near perfect levels, even on the first few trials of each day (Figure 1B, Supplementary Figure S7B).

\subsection{Consistent statistical features of population activity on each day} \label{sec:chap3_set_point}

Despite these changes in the activity of individual neurons, we noticed that consistent patterns were present in the population activity on each day. As shown above, neuronal activity that tiled the full trial duration was present on each day and was made up of different neurons across days (Figure 2A). The distribution of population activity across the trial was not uniform, but this distribution was highly similar across all days in a given population of neurons (Figure 5A-B). In addition, on each day, a decoder for trial type based on population activity achieved similar levels of performance and had similar distributions of performance across time points in the trial (Figure 5C-D). Interestingly, in each population of neurons from different mice, differences between mice were maintained across days. For example, the population of neurons in one mouse (red) had higher decoding accuracy of trial type than did the population of neurons in another mouse (green) across all days (Figure 5D). These differences were maintained with a similar shape across the duration of the trial (Figure 5C). Many other properties of population activity had similar distributions on each day, including for neuron-neuron activity correlations (Figure 5E-F), trial-trial population activity correlations (Figure 5G-H), estimated population firing rates (Figure 5I-J), and decoding accuracy of trial type for individual neurons (Figure 5K-L). These results indicate that even though properties of activity in individual neurons changed across time, the statistical features of population activity were largely consistent over weeks. Therefore, the population appeared to have a ?set point? of similar activity each day, using different neurons, and neurons in different ways, to achieve this steady state.

\subsection{Decoding of information from dynamic neuronal representations} \label{sec:chap3_peaks}

The changes in neuronal activity-behavior relationships over time raise questions about how information could be read out from such a dynamic neuronal population over days and weeks. One possibility is that the cells with the most consistent activity-behavior relationships are those that preferentially carry information for the readout. Alternatively, it could be possible that the activity in the cells with less consistent activity-behavior relationships also allows decoding of information over time. We investigated this issue by testing various decoding strategies for reading out the trial type on the basis of population activity.

\bigskip

We first trained and tested a linear decoder on each day separately using all neurons (as in Figure 5C-D). We found trial type information could be decoded throughout the duration of the trial, with higher decoding accuracies at the end of the trial, when the mouse executed a turn at the T-intersection (Figure 6A). We then compared the decoding performance using the cells with the most consistent activity-behavior relationships and the least consistent relationships, defined by exponential fits of model performance decay over time (from Figure 4G, see Methods). The cells with the least consistent activity-behavior relationships had better decoding accuracy throughout the majority of the trial than did the cells with the most consistent relationships. In the final segment of the trial, when the mouse executed a turn, decoding accuracies were similar between groups (Figure 6B). 

\bigskip

To analyze the stability of information in activity patterns, we tested decoding performance across days. We trained a decoder on a given day and tested it on subsequent days (Figure 6C). When considering a random subset of cells, decoding performance decreased as the interval between compared days increased. This result was present throughout the duration of the trial (Figure 6C). In the cells with the most consistent activity-behavior relationships, decoding performance was low and consistent across time for the majority of the trial (Figure 6C, left and middle). For the final segment of the trial, the decoding performance in these cells was high and consistent over days (Figure 6C, right). As expected, the performance of a decoder trained on one day and tested on other days decreased as a function of time for the cells with the least consistent activity-behavior relationships (Figure 6C). Interestingly, however, over intervals within one week, these cells performed better in the majority of the trial than the cells with the most consistent relationships (Figure 6C, left and middle). Together, these results indicate that the information in the population was not stable over time, but some information remained in the population for days and weeks, even in neurons with the least consistent activity patterns.

\bigskip

If the relevant information for the task needs to be read out near the time the mouse executes a turn, then it might be beneficial to weight strongly the activity of the cells with the most consistent activity-behavior relationships. In contrast, if information in the T-stem is more relevant for behavior, then weighting the activity of the cells with the less consistent relationships might be beneficial. In light of this reasoning, we returned to our optogenetic inactivation experiments and now inhibited PPC activity either during the first half of the trial or the second half of the trial. Interestingly, we found that when PPC activity was inhibited in the first half of the trial, the mouse?s performance was greatly impaired (Supplementary Figure S8). In contrast, inhibiting PPC activity during the second half the trial had no significant effect on the mouse?s performance (Supplementary Figure S8). This result is consistent with what has been reported previously in other tasks (Goard et al., 2016; Licata et al., 2016; Raposo et al., 2014). We note that it is difficult to interpret what this finding means in terms of PPC?s role in the task: PPC activity could be involved in the transformation of the sensory information into a behavioral action plan or in some aspect of visual processing or potentially other computations. Regardless, this finding suggests that it is possible that the task-relevant information in the cells with the least consistent activity-behavior relationships could be of importance for PPC?s role in this task.

\bigskip

These results suggest that to maintain high levels of information across time, an ideal readout would need to change in a coordinated manner with the encoding network. However, we wanted to test if it might be possible to identify a stable readout in the form of a single decision plane that could be used across all days to separate trials of different types on every day. We combined all imaging days together and trained a decoder on a subset of trials and tested this single decision boundary on other trials that were distributed across all days. We compared the performance of this combined-day decoder using only the neurons with the least consistent activity-behavior relationships, the most consistent relationships, or a random sample of all neurons (Figure 6D). In these cases, the cells with the least consistent relationships provided information at a similar level as the other groups and allowed decoding of trial type above chance levels. As expected, when the identities of the cells were shuffled independently on each day, the ability to find a stable readout decreased significantly, indicating that the decoding performance required the structure of the population activity over days (Figure 6D). This analysis therefore reveals that, for the binary classification of trial type over the time intervals examined, it is possible to find a stable readout of population activity that performs above chance levels, even from the most dynamic population of neurons. However, to achieve higher performance, a readout that changes dynamically with the encoding network would likely be necessary. 

\section{Discussion}
Our results reveal that during stable performance of a learned navigation task, the activity patterns in PPC were variable over the timescales of days and weeks. These findings indicate that through the course of learning, neuronal activity patterns in PPC did not converge to a single representation. Rather, there appeared to be a set of activity patterns in the PPC population that were similarly sufficient for the task. Importantly, many statistical features of the population activity were consistent across days, such that the population appeared to reach a set point. However, the PPC neurons that were used in this representation, and how these PPC neurons were used, changed across days.

\section{Acknowledgements}
We thank Ofer Mazor and members of the Harvey lab for comments on the manuscript. We thank Paola Patella and Matthias Minderer for contributing to the design and setup of the inactivation experiments. We thank Selmaan Chettih and Matthias Minderer for developing cell selection algorithms and software. We also thank the Research Instrumentation Core at Harvard Medical School. This work was supported by a Burroughs-Wellcome Fund Career Award at the Scientific Interface, the Searle Scholars Program, the New York Stem Cell Foundation, the Alfred P. Sloan Research Foundation, a NARSAD Brain and Behavior Research Young Investigator Award, NIH grants from the NIMH BRAINS program (R01MH107620) and NINDS (R01NS089521), an Armenise-Harvard Foundation Junior Faculty Grant, a Edward R. and Anne G. Lefler Center Predoctoral Fellowship and Junior Faculty Award, the Albert J. Ryan Fellowship, and the Stuart H.Q. and Victoria Quan Fellowship. C.D.H. is a New York Stem Cell Foundation Robertson Neuroscience Investigator. 

\section{Author contributions}
L.N.D and C.D.H. conceived of the project. N.L.P. designed and performed inactivation experiments and analyzed associated data. S.N.C. and M.M. designed cell selection algorithm and gui for extracting single session ROI maps. L.N.D. designed across session alignment algorithm and gui for aligning ROI maps across days. L.N.D and C.D.H designed all other experiments and analyses, and L.N.D. performed these experiments and analyses. L.N.D. and C.D.H. wrote the manuscript. 

\section{Data Analysis Methods}
\subsection{General Analysis Procedures}
For visualization of mean and single trial activity, activity was spatially binned into 66 segments (60 in the stem and 6 in the arms) followed by ~2 seconds (10 imaging frames) during the inter-trial interval. Spatially binned segments typically contained 1 imaging frame each per trial. Data was interpolated to fill in gaps in which a bin contained no imaging frames on a trial. These analyses were only used for fine-resolution measurements of locations of peak activity. For the majority of the analyses (all except Figure 2), we binned the data into larger segments (21 segments, 23 cm/bin). Neuronal activity and behavioral parameters were averaged in each bin in this case. Each bin typically contained 2-3 frames/trial. Unless otherwise noted, all analyses were performed on correct trials only. Correlation coefficients were calculated from Pearson?s correlations unless otherwise noted.

\subsection{Identification of Significant Peaks of Activity}
Here we used 60 spatial bins during the T-stem rather than 21 spatial bins because we were interested in achieving greater resolution of spatial reorganization. Mean activity across 60 spatial bins were calculated for correct white cue-left turn and black cue-right turn trials. To identify statistically significant peaks of activity, behavior data time courses were circle-shifted by a random amount relative to neuronal activity time courses, and new means were calculated for 1000 random shifts. All locations where the mean activity in the unshifted data was greater than activity in 950 shuffles for three consecutive bins were considered to contain a significant peak of activity. For all analyses where peaks were compared across days, we tracked peaks that were labelled with high confidence (unshifted data was greater than activity in 990 shuffles for three consecutive bins). Peaks were labelled as ?gained? or ?lost? if in the absent session, there was below 95 $\%$  significance for a peak at that location. We found this gap between thresholds for the presence or absence of a peak to be important for limiting measurement noise. By these criteria for change, we found peak consistency across odd and even trials within one session to be 83.2 ± 2.1  $\%$ .

\subsection{Encoding model }
On each day separately, we fit a Poisson Generalized Linear Model (Friedman et al., 2010) to the estimated event rates of each cell based on measured behavioral and task variables. While our estimated event rates were not necessarily Poisson distributed, mean responses scaled with the variance and rates were larger than zero, suggesting that the Poisson model was appropriate for our data.

\subsubsection{Model Parameters}
All measured behavioral and task-related variables were temporally averaged into bins to match the sampling rate of imaging frames. Variables include x and y position in the virtual world, running speed on the pitch and roll axes of the spherical treadmill, visual cue onset and offset locations, reward delivery events and trial end (Supplementary Figure S4). Variables provided input for basis functions that were distributed either in space or in time to produce 144 predictors in total. The maze was divided into 36 spatial boxcar filters and convolved with a Gaussian filter separately for right and left turn trials to make the first 72 filters. The onset of each visual cue contributed 4 basis functions (16 in total for all four cues) that spanned the first 2 seconds of the trial. For cue offset (delay period onset), 2 basis functions extended for 1 second preceding cue offset, and 4 basis functions extended for 2 seconds following cue offset (24 in total for all four cues). Running speed signals were extended 1 second forward and backward in time for translational and clockwise and counterclockwise rotational motion (4 filters forward and 4 filters backward for each of 3 speed signals for a total of 24 filters) to model predictive and responsive signals. Trial-end and reward events each contributed 4 basis functions that extended for 2 seconds forward in time (8 filters total). All temporal filters spanned 1 second, overlapping and evenly distributed within each set.

\subsubsection{Fitting}
We used the glmnet package in R to fit GLMs. Each day was divided into 10 evenly distributed chunks (first tenth of session, second tenth of session, and so on) and then sub-divided into 11 numbered pieces within each chunk. All pieces with the same number were then combined into groups 1-11. This resulted in 11 groups that contained data that was evenly distributed across the imaging session (Supplementary Figure S3). Seven of these groups were randomly chosen and used as cross validation folds during fitting, and the other three groups were combined and used to test model predictions (7 groups made up 73 $\%$  fitting and 3 groups made up 27 $\%$  testing predictions). For some figures, we compare models that were trained on a subset of data from a single session. First we divided data from a single session into halves, either interspersed chunks throughout the duration of the session or simply the first and second half of the session. We then treated these halves as independent sessions that were divided as we previously describe (73 $\%$  fitting and 27 $\%$  testing predictions). These models were only used for comparison to the appropriate opposite half within a single session. Parameters were fitted for each cell separately with elastic net regularization consisting of 10 $\%$  L2 and 90 $\%$  L1 methods. Model fitting was conducted on the Orchestra High Performance Compute Cluster at Harvard Medical School. This shared facility is partially supported by NIH through grant NCRR 1S10RR028832-01.
 
\subsubsection{Analysis of Model}
Deviance explained was used as the metric of model fit. It was calculated by comparing the activity predicted by the model to the actual activity, based on the average real and predicted activity levels on white cue-left and black cue-right turn trials. Deviance explained was calculated based only on data not included in the fitting procedure. It was compared to a null model in which the predicted event rate was 1 (the normalized mean rate of the entire fitting set). We also computed deviance explained using predictions of the full time series of activity for single frames. In this case, the distribution of fits was similar, except lower than for trial-averaged data, as expected. To determine whether a model prediction described test data significantly above chance, we compared the deviance explained to the distribution of deviance explained for models in which, before model fitting, the time series of neuronal activity was circle-shifted relative to the time series of behavior data. We found the upper limit of deviance explained in models that were fit on shuffled data to be 0.2 (for trial-averaged activity). Therefore, we determined models with greater than 0.2 deviance explained on test data to have predictions significantly above chance performance. Cells with activity that could not be significantly predicted by our models could still have behaviorally relevant activity patterns that were simply not described by our set of filters. Therefore, when we refer to cells having gained or lost activity-behavior relationships, we refer specifically to the set of relationships included in our models. \bigskipBy comparing model fits between any two days or between subsets of data from a single day, we could determine whether a given neuron?s activity-behavior relationship was consistent over time, gained or lost a relationship to a behavioral feature, or switched from encoding a particular set of behavioral features to encoding another. If models with significant predictions could be fit on each individual day?s data for a given pair of days and if the models also provided significant predictions of the other day?s activity, then we called the activity-behavior relationship consistent. If models with significant fits could be fit on each individual day?s data for a given pair of days and if the models did not provide significant predictions on the other day, we determined a switch in activity-behavior relationship had occurred. If only one day had a model that could predict the neuron?s activity significantly well, then we concluded that a gain or a loss of activity-behavior relationship had occurred. This approach works well when behavioral variables are not highly correlated. However, if behavioral variables are very highly correlated, then it is difficult for the model to determine to which variable weight should be attributed. If variables were highly correlated on one day but not correlated in another day, then incorrect assignments of switches in activity-behavior relationships could emerge. To be conservative and to account for any potential cases in which non-modeled variables were highly correlated with modeled variables (on some days but not others), we did not require symmetry in model performance across days for an activity-behavior relationship to be considered consistent. That is, if a model prediction on day i and day j both had significant predictions of activity and if the model from day i predicted well the activity from day j, but not vice versa, then a consistent activity-behavior relationship would still be considered to be present. In this case, if behavior variables x and y were highly correlated on day j but not on day i, then the model on day j might incorrectly attribute weights on day j leading to a poor prediction on day i. However, because the variables x and y were not highly correlated on day i, then the model would correctly attribute weights on day i, successfully predicting activity on day j despite having correlated variables x and y on day j. This method would still fail to identify a consistent activity-behavior relationship if the ?real? encoded feature (for example, mental state) was correlated with different filters in the model on each day. These subtle behavioral confounds are difficult to remove completely and should be considered in the interpretation of this work and most other behavioral studies. Through the use of virtual reality we could control the sensory environment and track behavioral metrics with great precision, incorporating these features into our models and thus minimizing the aforementioned concerns.

\subsubsection{Metric of consistency in activity-behavior relationships}We defined the consistency of activity-behavior relationships for each cell by the likelihood that an encoding model fit on a given day continued to provide significant predictions of the cell?s activity for days and weeks. We found the fraction of models that provided a significant prediction of a given cell?s activity over each interval between fitting and prediction sets (1-30 days). We then fit an exponential decay, weighting each point by the number of model comparisons available (for example, there were more model comparisons where ? days = 1 than ? days = 30). We only included cells that had significant fits on at least half of days where ? days = 0 because cells with a low starting point necessarily had slow decays because the fraction of significant model fits was bounded by zero.\subsubsection{Contribution of task and behavioral features to the activity of a cell}To calculate the contribution of each task and behavioral variable to a given model, we computed the standard deviation of the linear part of the model that was related to the behavioral variable of interest (the standard deviation of beta coefficients crossed with relevant behavioral filters of behavioral data). This provided us with the extent to which a behavioral variable modulated the activity of the neuron. For filter groupings in position/cue, velocity and ITI contribution calculation see Supplementary Figure S4.

\subsection{Decoding}
We used C-Support Vector Classification with a linear kernel for all decoders. For some decoders, we considered the activity of single cells (Figure 3 and 5K) or populations of cells (Figure 7) across the entire trial. In these cases, the decoder was trained using data from all 21 spatial bins in the trial. In other cases, in which we wanted to assess the time course of information, we trained decoders on each spatial bin separately using the activity of all neurons or subsets of neurons (Figure 5A and 6). When decoders incorporated a smaller number of cells (20 cells each for subgroups in Figure 6) we divided the maze into larger bins to account for the fact that each only had trial type information for a small portion of the trial. For decoding analyses, the data were divided into two-thirds for training/validation and one-third for testing. The regularization weight hyperparameter C was selected using a random search with 10-fold cross validation on a subset of training sets across mice. The specific setting of the hyperparameter did not greatly affect the accuracy of our decoders. The same hyperparameter value (C = 100) was used for all data sets. Significant decoding accuracies in Figure 3 were determined by bootstrap analysis in which behavioral data were circularly rotated relative to each cell?s neuronal activity. Cells in which real data performed better than 950 of 1000 shuffles were determined to have significant decoding accuracy. Using this statistical threshold, it is thus expected that 5 $\%$  of cells would have significant decoding accuracy by chance. 


 












